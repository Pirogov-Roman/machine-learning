# Машинное обучение 

#  ML - решает следюущую задачу
# Требуется подогнать заданный набор точек данными под некоторую функцию(отображение входа на выход), которая улавливает сигналы в данных и игнорирует помехи, а затем убедиться, что на новых данных найденная функция работает хорошо

# обучение с учителем (supervised learning)
# обучение без учителя (unsupervised learning)

# ОсУ - моделирует отношение между признаками и метками. Такие модели служат для предсказания меток на основе обучающих данных, маркированных. После построения модели можно использовать ее для присвоения меток ранее неизвестным данным

# - задачи классификации (метки дисрктеные)
# - задачи регрессии (метки/результат: непрерывные величины)

# ОбУ - моделирование признаки без меток. Такие модели служат для выявления структуры немаркерованных данных

# - задачи кластеризации(выделяет отдельные группы данных)
# - задача понижения размерности (поиск более сжатого представления данных)

# Существуют методы частичного обучения(semi-supervised learning). Не все данные промаркированы

# Методы относящиеся к обучению с подкреплением(reinforcement learning). Cистема обучения улучшает свои характеристики на основе взаимодейтсвия (обратной связи) со средой с которой она работает. При этом взаимодействии система получает сигналы (функции наград), которые несут в себе информацию насколько хорошо/плохо система решила задачу(с точки зрения среды). Итоговая награда не станет максимальной.

import seaborn as sns

iris = sns.load_dataset('iris')
# print(iris.head())
# print(type(iris))

# print(type(iris.values))
# print(iris.values.shape)
# print(iris.columns)
# print(iris.index)

# Строки - отдельные объекты - образцы(sample)
# Столбцы - признаки(features) - соответствуют конкретным наблюдениям
# Матрица признаков(features matrix) размер (число образцов х число признаков)
# Целевой массив, массив меток (targets) - одномерный массив (1 х число образцов)
# Зависимые (метка) и независимые переменные(признаки)

# Процесс построения системы машинного обучения:

# 1. Предварительная обработка
# - на вход поступают необработанные данные и метки
# - происходит выбор признаков, масштабирование признаков
# - понижение размерности
# - выборка образцов
# - на выход набор данных: обучающий, тестовый

# 2. Обучение
# - выблр модели
# - перекрестная проверка
# - метрики эффективности
# - оптимизация гиперпараметров. параметры, которые получаются не из данных, а я вляются характеристиками модели

# 3. Оценка и формирование финальной модели

# 4. Прогнозирование (использование модели)

# SciKit-learn

# 1. Выбираем класс модели
# 2. Устанавливаем гиперпараметры модели 
# 3. создаем матрицу признаков и целевой массив
# 4. Обучение модели fit()
# 5. применять модель к новым данным
# - predict() (c учителем)
# - predict() или transform() (без учителя)

# Обучение с учителем: линейная регрессия 

## Простая линейная регрессия 

# y = ax + b

import matplotlib.pyplot as plt
import numpy as np

# I
np.random.seed(1)
x = 10 * np.random.rand(50)

y = 2 * x - 1 + np.random.randn(50)
plt.scatter(x, y)
# II
from sklearn.linear_model import LinearRegression
model = LinearRegression(fit_intercept=True)#по умолчанию тру. это отвечает за гиперпараметр
X = x[:, np.newaxis]
model.fit(X, y)
x_ = np.linspace(0, 10, 30)
y_ = model.coef_[0] * x_ + model.intercept_

plt.plot(x_, y_)

xfit = np.linspace(-10, 10, 5)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(xfit, yfit)
plt.show()









